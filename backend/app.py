"""
Flask backend for Employee Onboarding Chatbot
Handles Azure OpenAI integration and function calling
"""

import os
import json
from flask import Flask, request, jsonify
from flask_cors import CORS
from openai import AzureOpenAI
from dotenv import load_dotenv

from mock_data import onboarding_faqs, mock_knowledge_base, mock_hr_policy
from functions import FUNCTION_DEFINITIONS, ALL_TOOLS, FORMAT_RESPONSE_TOOL, execute_function

# Load environment variables
load_dotenv()

# Initialize Flask app
app = Flask(__name__)
CORS(app)  # Enable CORS for React frontend

# Initialize Azure OpenAI client
client = AzureOpenAI(
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    api_version="2024-07-01-preview",  # Use fixed version for stability
)

DEPLOYMENT_NAME = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")


def create_system_prompt():
    """
    Create enhanced system prompt with few-shot examples and formatting guidelines
    """
    base_prompt = """B·∫°n l√† Tr·ª£ l√Ω Onboarding th√¥ng minh c·ªßa FPT Software. Nhi·ªám v·ª• c·ªßa b·∫°n l√† h·ªó tr·ª£ nh√¢n vi√™n m·ªõi trong qu√° tr√¨nh onboarding m·ªôt c√°ch ch·ªß ƒë·ªông v√† hi·ªáu qu·∫£.

## T√≠nh c√°ch
- Th√¢n thi·ªán, chuy√™n nghi·ªáp, nhi·ªát t√¨nh
- Ch·ªß ƒë·ªông h·ªó tr·ª£, kh√¥ng ch·ªâ ƒë·ª£i ƒë∆∞·ª£c h·ªèi
- Quan t√¢m ƒë·∫øn deadline v√† s·ª± ti·∫øn b·ªô c·ªßa nh√¢n vi√™n

## Quy t·∫Øc tr·∫£ l·ªùi

### 1. ƒê·ªãnh d·∫°ng ph·∫£n h·ªìi
- S·ª≠ d·ª•ng Markdown ƒë·ªÉ ƒë·ªãnh d·∫°ng r√µ r√†ng
- Danh s√°ch nhi·ªám v·ª•: d√πng bullet points v·ªõi emoji (‚úÖ cho Done, ‚è≥ cho Pending)
- Th√¥ng tin li√™n l·∫°c: hi·ªÉn th·ªã Email, Phone, Teams link r√µ r√†ng
- Ng√†y th√°ng: format DD/MM/YYYY
- Priority: d√πng emoji (üî¥ High, üü° Medium, üü¢ Low)

### 2. S·ª≠ d·ª•ng Functions
- Khi ng∆∞·ªùi d√πng h·ªèi v·ªÅ nhi·ªám v·ª• ‚Üí g·ªçi get_onboarding_tasks
- Khi ng∆∞·ªùi d√πng h·ªèi v·ªÅ manager/buddy ‚Üí g·ªçi get_employee_info
- Khi ng∆∞·ªùi d√πng b√°o ho√†n th√†nh task ‚Üí g·ªçi update_task_status
- Khi ng∆∞·ªùi d√πng mu·ªën k·∫øt n·ªëi v·ªõi ai ƒë√≥ ‚Üí g·ªçi send_introduction_message

### 3. Ch√†o h·ªèi ch·ªß ƒë·ªông
- Lu√¥n g·ªçi t√™n nh√¢n vi√™n khi bi·∫øt th√¥ng tin
- Ki·ªÉm tra v√† nh·∫Øc v·ªÅ nhi·ªám v·ª• s·∫Øp ƒë·∫øn h·∫°n
- ƒê·ªÅ xu·∫•t h√†nh ƒë·ªông ti·∫øp theo

### 4. X·ª≠ l√Ω kh√¥ng bi·∫øt
- N·∫øu kh√¥ng r√µ ho·∫∑c kh√¥ng c√≥ th√¥ng tin ‚Üí ƒë·ª´ng b·ªãa ƒë·∫∑t
- ƒê·ªÅ xu·∫•t li√™n h·ªá v·ªõi HR ho·∫∑c IT Support
- Format: "Em ch∆∞a c√≥ th√¥ng tin v·ªÅ [ch·ªß ƒë·ªÅ]. Anh/ch·ªã c√≥ mu·ªën em k·∫øt n·ªëi anh/ch·ªã v·ªõi b·ªô ph·∫≠n [HR/IT] ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ kh√¥ng?"

## V√≠ d·ª• FAQ

"""
    
    # Add few-shot examples from FAQ
    for i, faq in enumerate(onboarding_faqs[:4], 1):
        base_prompt += f"**Q{i}:** {faq['q']}\n**A{i}:** {faq['a']}\n\n"
    
    base_prompt += """
## V√≠ d·ª• format ph·∫£n h·ªìi t·ªët

**Danh s√°ch nhi·ªám v·ª•:**
‚úÖ G·∫∑p m·∫∑t Buddy (Ho√†n th√†nh)
‚è≥ Ho√†n th√†nh kh√≥a h·ªçc Security (H·∫°n: 25/10) - üî¥ ∆Øu ti√™n cao
‚è≥ Thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng dev (H·∫°n: 27/10) - üü° ∆Øu ti√™n trung b√¨nh

**Th√¥ng tin li√™n l·∫°c:**
üìß Email: cuong.tran@fsoft.com.vn
üìû Phone: +84 93 456 7890
üí¨ [Chat tr√™n Teams](https://teams.microsoft.com/l/chat/cuong.tran)

## Quy t·∫Øc X√°c nh·∫≠n (Confirmation)

**QUAN TR·ªåNG**: Tr∆∞·ªõc khi g·ªçi function `update_task_status`, PH·∫¢I h·ªèi x√°c nh·∫≠n:
1. Nh·∫≠n di·ªán task user mu·ªën update
2. H·ªèi x√°c nh·∫≠n: "Em th·∫•y c√≥ nhi·ªám v·ª• [t√™n task]. Anh x√°c nh·∫≠n ƒë√£ ho√†n th√†nh ƒë√∫ng kh√¥ng?"
3. CH·ªà g·ªçi function sau khi user x√°c nh·∫≠n (v√≠ d·ª•: "ƒë√∫ng", "yes", "ok")
4. Sau khi update, g·ªçi `get_next_task` ƒë·ªÉ g·ª£i √Ω vi·ªác ti·∫øp theo

**V√≠ d·ª• workflow:**
User: "T√¥i ho√†n th√†nh kh√≥a h·ªçc Security r·ªìi"
Bot: "Tuy·ªát v·ªùi! Em th·∫•y nhi·ªám v·ª• **[T01] Ho√†n th√†nh kh√≥a h·ªçc Security Awareness**. Anh x√°c nh·∫≠n ƒë√£ ho√†n th√†nh nhi·ªám v·ª• n√†y ƒë√∫ng kh√¥ng?"
User: "ƒê√∫ng r·ªìi"
Bot: [G·ªçi update_task_status] ‚Üí [G·ªçi get_next_task] ‚Üí Ph·∫£n h·ªìi v·ªõi nhi·ªám v·ª• ti·∫øp theo

## Knowledge Base - IT Support

"""
    
    # Add IT support knowledge
    for item in mock_knowledge_base["it_support"]:
        if "topic" in item:
            base_prompt += f"\n**{item['topic']}:**\n"
            for key, value in item.items():
                if key != "topic":
                    base_prompt += f"- {key.capitalize()}: {value}\n"
    
    base_prompt += "\n## Knowledge Base - HR Systems\n"
    
    # Add HR systems knowledge
    for item in mock_knowledge_base["hr_systems"]:
        base_prompt += f"\n**{item['name']}** ({item['system']}):\n"
        base_prompt += f"- Link: {item['link']}\n"
        base_prompt += f"- M√¥ t·∫£: {item['description']}\n"
        if "approval" in item:
            base_prompt += f"- Ph√™ duy·ªát: {item['approval']}\n"
        if "deadline" in item:
            base_prompt += f"- Deadline: {item['deadline']}\n"
        if "availability" in item:
            base_prompt += f"- Th·ªùi gian: {item['availability']}\n"
    
    base_prompt += "\n## Office Information\n"
    
    # Add office info
    for office in mock_knowledge_base["office_info"]:
        base_prompt += f"\n**{office['location']}:**\n"
        base_prompt += f"- ƒê·ªãa ch·ªâ: {office['address']}\n"
        base_prompt += f"- Gi·ªù l√†m vi·ªác: {office['working_hours']}\n"
        base_prompt += f"- Parking: {office['parking']}\n"
        base_prompt += f"- Canteen: {office['canteen']}\n"
    
    # ========== HR POLICY KNOWLEDGE BASE (Extended) ==========
    base_prompt += "\n\n## HR Policy - L∆∞∆°ng & Ph√∫c l·ª£i (Compensation & Benefits)\n"
    for key, value in mock_hr_policy["compensation"].items():
        base_prompt += f"- **{key}**: {value}\n"
    
    base_prompt += "\n**Ph√∫c l·ª£i (Benefits):**\n"
    for key, value in mock_hr_policy["benefits"].items():
        base_prompt += f"- **{key}**: {value}\n"
    
    base_prompt += "\n## HR Policy - Ngh·ªâ ph√©p & Ch·∫•m c√¥ng (Leave & Time-Off)\n"
    for key, value in mock_hr_policy["leave_policy"].items():
        base_prompt += f"- **{key}**: {value}\n"
    
    base_prompt += "\n## HR Policy - ƒê√†o t·∫°o & Ph√°t tri·ªÉn (Training & Career)\n"
    for key, value in mock_hr_policy["career"].items():
        base_prompt += f"- **{key}**: {value}\n"
    
    base_prompt += "\n## HR Policy - H·ªá th·ªëng N·ªôi b·ªô (Internal Systems)\n"
    for system, desc in mock_hr_policy["internal_systems"].items():
        base_prompt += f"- **{system}**: {desc}\n"
    
    base_prompt += "\n## HR Policy - Ch√≠nh s√°ch Chi ph√≠ (Expense Policy)\n"
    for key, value in mock_hr_policy["expense_policy"].items():
        base_prompt += f"- **{key}**: {value}\n"
    
    base_prompt += """

## Quy t·∫Øc Format Ph·∫£n h·ªìi (QUAN TR·ªåNG)

**B·∫ÆT BU·ªòC**: Sau khi ho√†n th√†nh t·∫•t c·∫£ c√°c function calls c·∫ßn thi·∫øt, PH·∫¢I s·ª≠ d·ª•ng tool `format_user_response` ƒë·ªÉ:
1. T·∫°o c√¢u tr·∫£ l·ªùi ch√≠nh (main_answer) v·ªõi format ƒë·∫πp
2. ƒê·ªÅ xu·∫•t 3 c√¢u h·ªèi/h√†nh ƒë·ªông ti·∫øp theo C√ì LI√äN QUAN ƒë·∫øn ng·ªØ c·∫£nh

**V√≠ d·ª• suggestions t·ªët:**
- N·∫øu v·ª´a tr·∫£ l·ªùi v·ªÅ tasks ‚Üí G·ª£i √Ω: "ƒê√°nh d·∫•u task ho√†n th√†nh", "Task n√†o s·∫Øp h·∫øt h·∫°n?"
- N·∫øu v·ª´a tr·∫£ l·ªùi v·ªÅ team ‚Üí G·ª£i √Ω: "Khi n√†o c√≥ meeting?", "Ai l√† team lead?"
- N·∫øu v·ª´a tr·∫£ l·ªùi v·ªÅ IT ‚Üí G·ª£i √Ω: "H∆∞·ªõng d·∫´n c√†i VPN", "Li√™n h·ªá IT support"

Suggestions ph·∫£i NG·∫ÆN G·ªåN (< 50 k√Ω t·ª±) v√† H√ÄNH ƒê·ªòNG ƒë∆∞·ª£c.

H√£y √°p d·ª•ng phong c√°ch tr√™n cho m·ªçi ph·∫£n h·ªìi. Lu√¥n nh·ªõ X√ÅC NH·∫¨N tr∆∞·ªõc khi update task.
"""
    
    return base_prompt


@app.route('/api/chat', methods=['POST'])
def chat():
    """
    Main chat endpoint
    Receives message history and returns assistant response
    """
    try:
        data = request.json
        messages = data.get('messages', [])
        
        if not messages:
            return jsonify({"error": "No messages provided"}), 400
        
        # Add system prompt if not present
        if not messages or messages[0].get("role") != "system":
            system_message = {
                "role": "system",
                "content": create_system_prompt()
            }
            messages.insert(0, system_message)
        
        # Step 1: Call Azure OpenAI with ALL tools (including format tool)
        response = client.chat.completions.create(
            model=DEPLOYMENT_NAME,
            messages=messages,
            functions=ALL_TOOLS,
            function_call="auto",
            temperature=0.7,
            max_tokens=800
        )
        
        response_message = response.choices[0].message
        
        # Check if LLM wants to call a function
        if response_message.function_call:
            function_name = response_message.function_call.name
            function_args = response_message.function_call.arguments
            
            # Case 1: Format tool - this is the final response
            if function_name == "format_user_response":
                try:
                    format_data = json.loads(function_args)
                    return jsonify({
                        "success": True,
                        "messages": messages,
                        "response": {
                            "role": "assistant",
                            "content": format_data.get("main_answer", ""),
                            "suggested_prompts": format_data.get("suggested_prompts", [])
                        }
                    })
                except json.JSONDecodeError:
                    # Fallback if format parsing fails
                    return jsonify({
                        "success": True,
                        "messages": messages,
                        "response": {
                            "role": "assistant",
                            "content": response_message.content or "Xin l·ªói, c√≥ l·ªói x·∫£y ra.",
                            "suggested_prompts": []
                        }
                    })
            
            # Case 2: Real function call (get_employee_info, update_task, etc.)
            # Execute the function
            function_result = execute_function(function_name, function_args)
            
            # Add assistant's function call to messages
            messages.append({
                "role": "assistant",
                "content": None,
                "function_call": {
                    "name": function_name,
                    "arguments": function_args
                }
            })
            
            # Add function result to messages
            messages.append({
                "role": "function",
                "name": function_name,
                "content": json.dumps(function_result, ensure_ascii=False)
            })
            
            # Step 2: Call LLM again and FORCE it to use format tool
            second_response = client.chat.completions.create(
                model=DEPLOYMENT_NAME,
                messages=messages,
                functions=ALL_TOOLS,
                function_call={"name": "format_user_response"},  # Force format tool
                temperature=0.7,
                max_tokens=800
            )
            
            final_message = second_response.choices[0].message
            
            # Parse format tool response
            if final_message.function_call and final_message.function_call.name == "format_user_response":
                try:
                    format_data = json.loads(final_message.function_call.arguments)
                    return jsonify({
                        "success": True,
                        "messages": messages,
                        "response": {
                            "role": "assistant",
                            "content": format_data.get("main_answer", ""),
                            "suggested_prompts": format_data.get("suggested_prompts", [])
                        }
                    })
                except json.JSONDecodeError:
                    pass
            
            # Fallback
            return jsonify({
                "success": True,
                "messages": messages,
                "response": {
                    "role": "assistant",
                    "content": final_message.content or "ƒê√£ x·ª≠ l√Ω xong.",
                    "suggested_prompts": []
                }
            })
        
        # No function call - should not happen with format tool, but handle it
        return jsonify({
            "success": True,
            "messages": messages,
            "response": {
                "role": "assistant",
                "content": response_message.content or "Xin ch√†o!",
                "suggested_prompts": []
            }
        })
        
    except Exception as e:
        print(f"Error in chat endpoint: {str(e)}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@app.route('/api/greeting', methods=['POST'])
def get_greeting():
    """
    Generate proactive greeting for a specific employee
    Checks for urgent tasks and creates personalized welcome message
    """
    try:
        data = request.json
        employee_id = data.get('employee_id', 'E123')  # Default to E123
        
        from functions import get_employee_info, check_urgent_tasks
        
        # Get employee info
        emp_result = get_employee_info(employee_id)
        if not emp_result.get("success"):
            return jsonify({
                "success": False,
                "error": "Employee not found"
            }), 404
        
        employee = emp_result["data"]
        name = employee["name"].split()[-1]  # Get first name
        
        # Check for urgent tasks
        urgent_result = check_urgent_tasks(employee_id)
        urgent_tasks = urgent_result.get("urgent_tasks", [])
        
        # Build greeting message
        greeting = f"üëã Ch√†o {name}! Em l√† Tr·ª£ l√Ω Onboarding c·ªßa FPT Software.\n\n"
        
        if urgent_tasks:
            if len(urgent_tasks) == 1:
                task = urgent_tasks[0]
                days_text = "h√¥m nay" if task["days_left"] == 0 else f"trong {task['days_left']} ng√†y t·ªõi"
                greeting += f"‚ö†Ô∏è Em th·∫•y c√≥ **{task['task']}** s·∫Øp ƒë·∫øn h·∫°n {days_text}. "
                greeting += "Anh nh·ªõ ho√†n th√†nh nh√©!\n\n"
            else:
                greeting += f"‚ö†Ô∏è Em th·∫•y anh c√≥ **{len(urgent_tasks)} nhi·ªám v·ª•** s·∫Øp ƒë·∫øn h·∫°n. "
                greeting += "Anh c√≥ mu·ªën xem chi ti·∫øt kh√¥ng?\n\n"
        
        greeting += "Em c√≥ th·ªÉ gi√∫p g√¨ cho anh h√¥m nay?"
        
        return jsonify({
            "success": True,
            "greeting": greeting,
            "employee": {
                "id": employee_id,
                "name": employee["name"]
            },
            "urgent_tasks_count": len(urgent_tasks)
        })
        
    except Exception as e:
        print(f"Error generating greeting: {str(e)}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@app.route('/api/health', methods=['GET'])
def health():
    """Health check endpoint"""
    return jsonify({
        "status": "healthy",
        "service": "Employee Onboarding Chatbot API"
    })


if __name__ == '__main__':
    # Check for required environment variables
    required_vars = [
        "AZURE_OPENAI_ENDPOINT",
        "AZURE_OPENAI_API_KEY",
        "AZURE_OPENAI_DEPLOYMENT_NAME"
    ]
    
    missing_vars = [var for var in required_vars if not os.getenv(var)]
    
    if missing_vars:
        print("‚ö†Ô∏è  Warning: Missing environment variables:")
        for var in missing_vars:
            print(f"   - {var}")
        print("\nPlease create a .env file based on .env.example")
    else:
        print("‚úÖ All environment variables loaded")
    
    # Get port from environment variable (for deployment) or default to 5000
    port = int(os.getenv('PORT', 5000))
    host = os.getenv('HOST', '0.0.0.0')
    
    print(f"\nüöÄ Starting Flask server on {host}:{port}")
    app.run(debug=False, host=host, port=port)
